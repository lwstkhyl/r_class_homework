---
title: "talk06 练习与作业"
documentclass: ctexart
output:
  rticles::ctex:
    fig_caption: yes
    number_sections: yes
    toc: true
    toc_depth: 2
  word_document: default
  html_document:
    df_print: paged
knit: (
  function(inputFile, encoding) { 

    pSubTitle <- 'talk06-homework'

    rmarkdown::render( 
      input       = inputFile, 
      encoding    = encoding, 
      params      = list(sub_title = pSubTitle),      
      output_file = pSubTitle) })
---

## 练习和作业说明

将相关代码填写入以 \`\`\`{r} \`\`\` 标志的代码框中，运行并看到正确的结果；

完成后，用工具栏里的"Knit"按键生成PDF文档；

**将PDF文档**改为：**`姓名-学号-talk06作业.pdf`**，并提交到老师指定的平台/钉群。

## Talk06 及 talk06-practices 内容回顾

1.  tidyr\
2.  3个生信任务的R解决方案
3.  forcats

## 练习与作业：用户验证

请运行以下命令，验证你的用户名。

**如你当前用户名不能体现你的真实姓名，请改为拼音后再运行本作业！**

```{r}
Sys.info()[["user"]]
Sys.getenv("HOME")
```

## 练习与作业1：tidyr

------------------------------------------------------------------------

### **使用 `grades` 变量做练习**

1.  装入`grades`变量；

`library(dplyr);`

`grades <- read_tsv( file = "data/talk05/grades.txt" );`

2.  使用 `tidyr`包里的 `pivot_longer` 和 `pivot_wider` 函数对 `grades` 变量进行宽长转换；

```{r}
library(dplyr)
library(readr)
library(tidyr)
grades <- read_tsv( file = "../data/talk05/grades.txt" )
grades#现在grades是长数据
#长变宽
grades_wide <- grades %>% 
  pivot_wider( names_from = "course", values_from = "grade" )
grades_wide 
#宽变长
grades_long <- grades_wide %>%
  pivot_longer(- name, names_to = "course", values_to = "grade")
grades_long
```

3.  使用 `pivot_longer` 时，有时会产生 `na` 值，如何使用此函数的参数去除带 `na` 的行？

```{r}
grades_long_drop_na <- grades_wide %>%
  pivot_longer(- name, names_to = "course", values_to = "grade",values_drop_na = TRUE)
grades_long_drop_na
```

4.  以下代码有什么作用？

`grades %>% complete( name, course )`

答：complete函数用于把隐式的缺失值转换成正常显示的缺失值。把grades按name和course分组，因为有3种name和5种course，分组后应有15行，而原数据只有9行；所以按此分组，原数据存在隐式的缺失值，complete可以将隐式缺失显示出来，使结果有15行，多出来的6行的grade列用NA代替

## 练习与作业2：作图

------------------------------------------------------------------------

### **用下面的数据作图**

1.  利用下面代码读取一个样本的宏基因组相对丰度数据

<!-- -->

```{r}
library(ggplot2)
library(ggforce)
library(forcats)
library(tidyverse)
library(tidytidbits)
#1
abu <- 
  read_delim(
    file = "../data/talk06/relative_abundance_for_RUN_ERR1072629_taxonlevel_species.txt",
    delim = "\t", quote = "", comment = "#");
head(abu)
```

2.  取前5个丰度最高的菌，将其它的相对丰度相加并归为一类 `Qita`；

3.  用得到的数据画如下的空心pie chart:

![make a pie chart like this using the meteagenomics data](../images/talk06/121-ggplot-pie-chart-donut-chart-1.png){height="50%"}

```{r}
#2
abu.dat <- abu %>% 
  arrange(desc(relative_abundance)) %>%
  lump_rows(scientific_name,relative_abundance,n=5,other_level="Qita")
abu.dat
#3--以下大部分代码来自网络
#添加角度
A_pies4 <- cross_join(abu.dat,
 abu.dat %>%
 summarize(Cnt_total = sum(relative_abundance))) %>%
 mutate(end_angle = 2*pi*cumsum(relative_abundance)/Cnt_total,
 start_angle = lag(end_angle, default = 0),
 mid_angle = 0.5*(start_angle + end_angle))
#添加位置
rlabel = 0.6 
A_pies4 <- mutate(A_pies4,
 hjust = ifelse(mid_angle>pi, 1, 0),
 vjust = ifelse(mid_angle<pi/2 | mid_angle>3*pi/2, 0, 1))
rlabel = 1.05
#作图
ggplot(A_pies4) +
 geom_arc_bar(aes(x0 = 0, y0 = 0, r0 = 1, r = 2,
 start = start_angle, end = end_angle, fill = scientific_name))+
 geom_text(aes(x = rlabel*sin(mid_angle), 
                     y = rlabel*cos(mid_angle), 
                     label = round(relative_abundance,1),  #round(relative_abundance,1)中的1是保留到小数点后的位数
 hjust = hjust, vjust = vjust),nudge_x = 0,  #nudge_x是文字在离圆心多远处显示
 show.legend = FALSE) +
 coord_fixed() +
  scale_fill_manual(values = c('#E5D2DD', '#53A85F', '#F1BB72', '#F3B1A0', 
                               '#D6E7A3', '#57C3F3', '#476D87',
                               '#E59CC4', '#AB3282', '#23452F', '#BD956A'))+
 theme_void()+
 theme(plot.title = element_text(size = 14, hjust = 0.5))
```

------------------------------------------------------------------------

### **使用`starwars`变量做图**

1.  统计 `starwars` 中 `hair_color` 的种类与人数时，可用下面的代码：

但是，怎么做到**按数量从小到大**排序？

```{r}
library(dplyr)
library(ggplot2)
library(forcats)
ggplot(starwars, aes(x = hair_color)) + 
  geom_bar() + 
  coord_flip()
```

```{r}
haircolor_count <- starwars %>%
  group_by(hair_color) %>%
  summarise(count=length(hair_color))
#统计个数用length（当用n_distinct不行时）
haircolor_count[[13,1]] <- "NA"  #把缺失值NA改成字符串“NA”，方便作图
ggplot(haircolor_count, aes(x=fct_reorder(hair_color,count,.desc = F),
                     y=count)) +
  xlab("hair_color") +
  geom_bar(stat = "identity") + 
#当出现tat_count() can only have an x or y aesthetic.报错时加stat = "identity"
  coord_flip()
```

2.  统计 `skin_color` 时，将出现频率小于0.05（即5%）的颜色归为一类`Others`，按出现次数排序后，做与上面类似的 barplot；

```{r}
haircolor_count_filter <- haircolor_count %>%
  arrange(count) %>%
  filter(count>nrow(starwars)*0.05)
#haircolor_count_filter选出频率>0.05的hair_color
haircolor_count_others <- haircolor_count %>%
    arrange(desc(count)) %>% 
    lump_rows(hair_color,count,n=nrow(haircolor_count_filter),other_level="Others")
#lump_rows函数中的n是把前n行保留，后面行相加合并，取之前选出来频率>0.05的hair_color的个数
ggplot(haircolor_count_others, aes(x=fct_reorder(hair_color,count,.desc = F),
                     y=count)) +
  xlab("hair_color") +
  geom_bar(stat = "identity") +
  coord_flip()
```

3.  使用 `2` 的统计结果，但画图时，调整 bar 的顺序，使得 `Others` 处于第4的位置上。提示，可使用 `fct_relevel` 函数；

```{r}
haircolor_count_others$hair_color <- fct_relevel(
  fct_reorder(haircolor_count_others$hair_color,haircolor_count_others$count,.desc = F),
  "NA","black","brown","Others")
ggplot(haircolor_count_others, aes(x=hair_color,y=count)) +
  xlab("hair_color") +
  geom_bar(stat = "identity") 
```

## 练习与作业3：数据分析

------------------------------------------------------------------------

### **使用 STRING PPI 数据分析并作图**

1.  使用以下代码，装入PPI数据；

<!-- -->

```{r}
ppi <- read_delim( file = "../data/talk06/ppi900.txt.gz", col_names = T, 
                   delim =  "\t", quote = "" );
head(ppi)
```

2.  **随机挑选**一个基因，得到类似于本章第一部分的互作网络图；

```{r}
library( igraph )
toppart <- ppi %>% 
  filter( gene1 == "KIF23" ) %>% 
  arrange( desc( score ) ) %>%
  slice( 1:10 )#取前10行（与KIF23最有关的10个基因），要不数据太多
genes <- unique( c( "KIF23", toppart$gene2 ) ) 
#得到"KIF23"与gene2的并集genes，共11个基因
netdata <- ppi %>% filter( gene1 %in% genes & gene2 %in% genes )
#挑选出gene1和gene2列都在genes里的行（11个基因的相互联系）
#因为是网络图，不能只是KIF23与其它基因的关系，还有其它基因之间的联系，
#所以要再在ppi总集里取10个基因
netdata.nr <- 
  netdata %>% 
  mutate( group  =  
            if_else( gene1 > gene2, 
                     str_c( gene1, gene2, sep = "-" ), 
                     str_c( gene2, gene1, sep = "-" ) ) ) %>% 
  group_by( group ) %>% slice( 1 ) #去除重复数据（课件内容）
netnet.nr <- graph_from_data_frame( netdata.nr, directed = FALSE )
plot(netnet.nr)
```

### **对宏基因组 相对丰度数据 进行分析**

1.`data/talk06` 目录下有6个文本文件，每个包含了一个宏基因组样本的分析结果：

```         
relative_abundance_for_curated_sample_PRJEB6070-DE-073_at_taxonlevel_species.txt
relative_abundance_for_curated_sample_PRJEB6070-DE-074_at_taxonlevel_species.txt
relative_abundance_for_curated_sample_PRJEB6070-DE-075_at_taxonlevel_species.txt
relative_abundance_for_curated_sample_PRJEB6070-DE-076_at_taxonlevel_species.txt
relative_abundance_for_curated_sample_PRJEB6070-DE-077_at_taxonlevel_species.txt
```

2.  分别读取以上文件，提取`scientific_name`和`relative_abundance`两列；

3.  添加一列为样本名，比如`PRJEB6070-DE-073`, `PRJEB6070-DE-074` ... ；

4.  以`scientific_name`为`key`，将其内容合并为一个 `data.frame` 或 `tibble`，其中每行为一个样本，每列为样本的物种相对丰度。注意：用 `join` 或者 `spread`都可以，只要能解决问题。

5.  将`NA`值改为0。

```{r}
#读取文件
col_name <- c("ncbi_taxon_id","taxon_rank_level","relative_abundance","scientific_name")
file1 <- read.table("data/talk06/relative_abundance_for_curated_sample_PRJEB6070-DE-073_at_taxonlevel_species.txt",
                    skip=3,sep = "\t",na.strings = NA,
                    header = TRUE,quote="",
                    col.names = col_name) %>%
  select(scientific_name,relative_abundance) %>% #提取指定列
  mutate(sample_name="PRJEB6070-DE-073") #添加样本名列
file2 <- read.table("data/talk06/relative_abundance_for_curated_sample_PRJEB6070-DE-074_at_taxonlevel_species.txt",
                    skip=3,sep = "\t",na.strings = NA,
                    header = TRUE,quote="",
                    col.names = col_name) %>%
  select(scientific_name,relative_abundance) %>%
  mutate(sample_name="PRJEB6070-DE-074")
file3 <- read.table("data/talk06/relative_abundance_for_curated_sample_PRJEB6070-DE-075_at_taxonlevel_species.txt",
                    skip=3,sep = "\t",na.strings = NA,
                    header = TRUE,quote="",
                    col.names = col_name) %>%
  select(scientific_name,relative_abundance) %>%
  mutate(sample_name="PRJEB6070-DE-075")
file4 <- read.table("data/talk06/relative_abundance_for_curated_sample_PRJEB6070-DE-076_at_taxonlevel_species.txt",
                    skip=3,sep = "\t",na.strings = NA,
                    header = TRUE,quote="",
                    col.names = col_name) %>%
  select(scientific_name,relative_abundance) %>%
  mutate(sample_name="PRJEB6070-DE-076")
file5 <- read.table("data/talk06/relative_abundance_for_curated_sample_PRJEB6070-DE-077_at_taxonlevel_species.txt",
                    skip=3,sep = "\t",na.strings = NA,
                    header = TRUE,quote="",
                    col.names = col_name) %>%
  select(scientific_name,relative_abundance) %>%
  mutate(sample_name="PRJEB6070-DE-077")
res <- bind_rows(file1,file2,file3,file4,file5)#合并dataframe
res <- as.tibble(res)#将dataframe转为tibble
res_wider <- res %>%
  distinct(sample_name,scientific_name,.keep_all = T) %>%
#去除sample_name和scientific_name都重复的行，即同一个样本中sci_name相同的重复行，
#否则变宽时会有多个值对应一个位置，让该处的值为一个list
  complete(sample_name,scientific_name) %>%
#将隐式缺失值转为显式
  pivot_wider(names_from = "sample_name",values_from = "relative_abundance")
#sample_name为列名，relative_abundance为列值
res_wider[is.na(res_wider)] <- 0
#将所有的NA替换为0,is.na函数返回tibble中所有NA的索引
head(res_wider,n=10)
```
